{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UniVR-DH/ADHLab/blob/main/lecture01-solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Crawling with Beautifulsoup4 and  Wikipedia Python APIs to create a document collection\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1m_EMdnI5C826kgqK7r5vB4TXnB0-Wq7W\" alt=\"Intestazione con loghi istituzionali\" width=\"525\"/>\n",
        "\n",
        "| Docente      | Insegnamento | Anno Accademico    |\n",
        "| :---        |    :----   |          ---: |\n",
        "| Matteo Lissandrini      | Laboratorio Avanzato di Informatica Umanistica       | 2023/2024   |"
      ],
      "metadata": {
        "id": "4MNB7PsQ99Bx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing additional packages"
      ],
      "metadata": {
        "id": "0iPoLBUQPSsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install wikipedia-api\n",
        "%pip install beautifulsoup4\n",
        "%pip install nltk"
      ],
      "metadata": {
        "id": "pmOC8TtR5Wm5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c25a4802-5194-4e78-a59a-62c1cc57c9d6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wikipedia-api in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from wikipedia-api) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->wikipedia-api) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->wikipedia-api) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->wikipedia-api) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->wikipedia-api) (2023.7.22)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing some basic required packages"
      ],
      "metadata": {
        "id": "M1Fok_kRPbQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gzip\n",
        "import string\n",
        "import numpy as np\n",
        "import requests\n",
        "import regex as re"
      ],
      "metadata": {
        "id": "miPm486TF629"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Crawling content with Beautifulsoup4\n",
        "#### Select a webpage, download its content, parse the HTML to extract the text"
      ],
      "metadata": {
        "id": "oZhJyAA7U5B0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "page = requests.get('https://en.wikipedia.org/wiki/New_York_City')\n",
        "\n",
        "# Create a BeautifulSoup object\n",
        "soup = BeautifulSoup(page.text, 'html.parser')\n",
        "\n",
        "# Pull text from all instances of <p> tag within BodyText div\n",
        "all_p_items = soup.find(class_='mw-body').find_all('p')\n",
        "print(len(all_p_items))\n",
        "print(all_p_items[0])\n",
        "print(all_p_items[0].get_text())\n",
        "print('    ----    ')\n",
        "print(all_p_items[1])\n",
        "print(all_p_items[1].get_text())"
      ],
      "metadata": {
        "id": "5NC2R7f5PtwM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "341a4fe8-e5c9-42d9-db9f-fa2ab6aad95c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "161\n",
            "<p class=\"mw-empty-elt\">\n",
            "</p>\n",
            "\n",
            "\n",
            "    ----    \n",
            "<p><b>New York</b>, often called <b>New York City</b><sup class=\"reference\" id=\"cite_ref-12\"><a href=\"#cite_note-12\">[b]</a></sup> or simply <b>NYC</b>, is the <a href=\"/wiki/List_of_United_States_cities_by_population\" title=\"List of United States cities by population\">most populous city</a> in the <a href=\"/wiki/United_States\" title=\"United States\">United States</a>. With a population of 8,804,190 distributed over 300.46 square miles (778.2 km<sup>2</sup>) in 2020, the city is the <a href=\"/wiki/List_of_United_States_cities_by_population_density\" title=\"List of United States cities by population density\">most densely populated</a> major city in the United States. NYC is more than twice as populous as <a href=\"/wiki/Los_Angeles\" title=\"Los Angeles\">Los Angeles</a>, the nation's second-most populous city. New York City is at the southern tip of <a href=\"/wiki/New_York_(state)\" title=\"New York (state)\">New York State</a> and is situated on <a href=\"/wiki/New_York_Harbor\" title=\"New York Harbor\">one of the world's largest natural harbors</a>. The city comprises <a href=\"/wiki/Boroughs_of_New_York_City\" title=\"Boroughs of New York City\">five boroughs</a>, each of which is coextensive with a respective <a href=\"/wiki/List_of_counties_in_New_York\" title=\"List of counties in New York\">county</a>. The five boroughs, which were created in 1898 when local governments were <a href=\"/wiki/City_of_Greater_New_York\" title=\"City of Greater New York\">consolidated</a> into a single municipality, are: <a href=\"/wiki/Brooklyn\" title=\"Brooklyn\">Brooklyn</a> (Kings County), <a href=\"/wiki/Queens\" title=\"Queens\">Queens</a> (Queens County), <a href=\"/wiki/Manhattan\" title=\"Manhattan\">Manhattan</a> (New York County), <a href=\"/wiki/The_Bronx\" title=\"The Bronx\">the Bronx</a> (Bronx County), and <a href=\"/wiki/Staten_Island\" title=\"Staten Island\">Staten Island</a> (Richmond County).<sup class=\"reference\" id=\"cite_ref-13\"><a href=\"#cite_note-13\">[11]</a></sup> New York City is a <a href=\"/wiki/Global_city\" title=\"Global city\">global city</a> and a <a href=\"/wiki/Culture_of_New_York_City\" title=\"Culture of New York City\">cultural</a>, <a href=\"/wiki/Economy_of_New_York_City\" title=\"Economy of New York City\">financial</a>, <a class=\"mw-redirect\" href=\"/wiki/High-tech\" title=\"High-tech\">high-tech</a>,<sup class=\"reference\" id=\"cite_ref-NewYorkCityDestinationNumberOneTechHub_14-0\"><a href=\"#cite_note-NewYorkCityDestinationNumberOneTechHub-14\">[12]</a></sup> <a href=\"/wiki/The_Entertainment_Capital_of_the_World\" title=\"The Entertainment Capital of the World\">entertainment</a>, and <a href=\"/wiki/Media_in_New_York_City\" title=\"Media in New York City\">media</a> center with a significant influence on commerce, <a href=\"/wiki/Healthcare_in_New_York_City\" title=\"Healthcare in New York City\">health care</a>, <a href=\"/wiki/List_of_cities_by_scientific_output#Leading_cities_in_different_fields\" title=\"List of cities by scientific output\">scientific output</a>, <a href=\"/wiki/List_of_biotech_and_pharmaceutical_companies_in_the_New_York_metropolitan_area\" title=\"List of biotech and pharmaceutical companies in the New York metropolitan area\">life sciences</a>,<sup class=\"reference\" id=\"cite_ref-NYCLifeSciencesCapital_15-0\"><a href=\"#cite_note-NYCLifeSciencesCapital-15\">[13]</a></sup><sup class=\"reference\" id=\"cite_ref-NYCHealthCareLifeSciences_16-0\"><a href=\"#cite_note-NYCHealthCareLifeSciences-16\">[14]</a></sup> research, technology, <a href=\"/wiki/Education_in_New_York_City\" title=\"Education in New York City\">education</a>, <a href=\"/wiki/Politics_of_New_York_City\" title=\"Politics of New York City\">politics</a>, <a href=\"/wiki/Tourism_in_New_York_City\" title=\"Tourism in New York City\">tourism</a>, <a href=\"/wiki/Cuisine_of_New_York_City\" title=\"Cuisine of New York City\">dining</a>, art, <a href=\"/wiki/Fashion_capital\" title=\"Fashion capital\">fashion</a>, and <a class=\"mw-redirect\" href=\"/wiki/Sports_in_New_York_City\" title=\"Sports in New York City\">sports</a>. Home to the <a href=\"/wiki/Headquarters_of_the_United_Nations\" title=\"Headquarters of the United Nations\">headquarters of the United Nations</a>, New York is an important center for <a href=\"/wiki/Diplomacy\" title=\"Diplomacy\">international diplomacy</a>,<sup class=\"reference\" id=\"cite_ref-17\"><a href=\"#cite_note-17\">[15]</a></sup><sup class=\"reference\" id=\"cite_ref-18\"><a href=\"#cite_note-18\">[16]</a></sup> and it is sometimes described as the world's most important city<sup class=\"reference\" id=\"cite_ref-NYCWorld'sMostImportantCity2_19-0\"><a href=\"#cite_note-NYCWorld'sMostImportantCity2-19\">[17]</a></sup> and the capital of the world.<sup class=\"reference\" id=\"cite_ref-NYCTheCapitaloftheWorld_20-0\"><a href=\"#cite_note-NYCTheCapitaloftheWorld-20\">[18]</a></sup><sup class=\"reference\" id=\"cite_ref-NewYorkCapitaloftheWorld2_21-0\"><a href=\"#cite_note-NewYorkCapitaloftheWorld2-21\">[19]</a></sup>\n",
            "</p>\n",
            "New York, often called New York City[b] or simply NYC, is the most populous city in the United States. With a population of 8,804,190 distributed over 300.46 square miles (778.2 km2) in 2020, the city is the most densely populated major city in the United States. NYC is more than twice as populous as Los Angeles, the nation's second-most populous city. New York City is at the southern tip of New York State and is situated on one of the world's largest natural harbors. The city comprises five boroughs, each of which is coextensive with a respective county. The five boroughs, which were created in 1898 when local governments were consolidated into a single municipality, are: Brooklyn (Kings County), Queens (Queens County), Manhattan (New York County), the Bronx (Bronx County), and Staten Island (Richmond County).[11] New York City is a global city and a cultural, financial, high-tech,[12] entertainment, and media center with a significant influence on commerce, health care, scientific output, life sciences,[13][14] research, technology, education, politics, tourism, dining, art, fashion, and sports. Home to the headquarters of the United Nations, New York is an important center for international diplomacy,[15][16] and it is sometimes described as the world's most important city[17] and the capital of the world.[18][19]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "punct_regex = re.compile('[{}]'.format(re.escape(string.punctuation))) # Regex matching any punctuation\n",
        "space_regex = re.compile(' +') # Regex matching whitespace\n",
        "\n",
        "text = punct_regex.sub(' ', soup.find(class_='mw-body').get_text())\n",
        "text = space_regex.sub(' ', text).lower()  # convert to lowercase\n",
        "lines = [\n",
        "    line.strip()\n",
        "    for line in text.split(\"\\n\")\n",
        "    if line.strip() != \"\" # Skip empty lines\n",
        "]\n",
        "# Store lines\n",
        "print(len(lines))\n",
        "print(lines[0])\n",
        "print(lines[1])\n",
        "print(lines[1290])"
      ],
      "metadata": {
        "id": "tJjalkcaSYyY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f12843ea-333c-456e-c5a9-a53a598151e0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2940\n",
            "toggle the table of contents\n",
            "new york city\n",
            "consulate general of iceland new york culture consulate general of iceland new york archived from the original on february 5 2013 retrieved july 23 2023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######\n",
        "# TODO: Open the wikipedia page for New York, select a sentence, can you find at which line it appears?\n",
        "######\n",
        "\n",
        "f = 'substantially by human intervention'\n",
        "\n",
        "for pos, line in enumerate(lines):\n",
        "  if f in line:\n",
        "    print(pos, line)\n",
        ""
      ],
      "metadata": {
        "id": "UQFpTUapUG07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "972c6ae2-a670-4079-c6ec-35fb989d647a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "106 the city s land has been altered substantially by human intervention with considerable land reclamation along the waterfronts since dutch colonial times reclamation is most prominent in lower manhattan with developments such as battery park city in the 1970s and 1980s 140 some of the natural relief in topography has been evened out especially in manhattan 141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######\n",
        "# TODO: Complete the code,\n",
        "#   a) split a line in single words, compute word frequency\n",
        "#   b) compute word frequency of all words across all lines\n",
        "#\n",
        "# Try out: https://docs.python.org/3/library/collections.html#collections.Counter\n",
        "#\n",
        "######\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "print(len(lines[1290].split(' ')))\n",
        "words = set( w for w in lines[1290].split(' '))\n",
        "print(len(words))\n",
        "print(words)\n",
        "\n",
        "word_count = Counter(lines[1290].split(' '))\n",
        "print(word_count)\n",
        "\n",
        "#word_count.most_common(2)\n",
        "\n",
        "word_count = Counter()\n",
        "for line in lines:\n",
        "  word_count.update(line.split(' '))\n",
        "\n",
        "word_count.most_common(10)\n"
      ],
      "metadata": {
        "id": "Gi4hqd9sinL2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0582da9-8c89-46ad-88f8-4400b339c0f9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25\n",
            "19\n",
            "{'consulate', 'culture', 'of', 'york', 'february', 'archived', 'new', 'retrieved', '5', '2013', 'on', 'general', 'iceland', 'original', '2023', 'july', 'from', '23', 'the'}\n",
            "Counter({'consulate': 2, 'general': 2, 'of': 2, 'iceland': 2, 'new': 2, 'york': 2, 'culture': 1, 'archived': 1, 'from': 1, 'the': 1, 'original': 1, 'on': 1, 'february': 1, '5': 1, '2013': 1, 'retrieved': 1, 'july': 1, '23': 1, '2023': 1})\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 2045),\n",
              " ('new', 1028),\n",
              " ('of', 977),\n",
              " ('york', 895),\n",
              " ('in', 800),\n",
              " ('and', 741),\n",
              " ('city', 695),\n",
              " ('retrieved', 457),\n",
              " ('s', 366),\n",
              " ('to', 347)]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Accessing Links in the page"
      ],
      "metadata": {
        "id": "1F_ewMNEVA2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_a_items = soup.find(class_='mw-body').find_all('a')\n",
        "print(len(all_a_items))\n",
        "for a in all_a_items:\n",
        "  href = a.get('href')\n",
        "  if href is not None and href.startswith('/wiki/') :\n",
        "    print(href)"
      ],
      "metadata": {
        "id": "oZgJPxHhQ9F7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######\n",
        "# TODO: Create a dictionary of /wiki/ links, and count how many times they appear in the page, which are the top-5 most frequent links?\n",
        "######\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "h1-fH47yRtkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######\n",
        "# TODO: Pick the most frequent /wiki/ link from the above dictionary,\n",
        "# download its page content and extract all links,\n",
        "# do you find links in common ?\n",
        "######\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "x7UTbGzLUd4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extract content from Wikipedia with the Wikipedia APIs"
      ],
      "metadata": {
        "id": "nkAYwP-5U0rU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wikipediaapi\n",
        "## EDIT Down There: put your name and email for the Wikipedia logs\n",
        "wapi_text = wikipediaapi.Wikipedia('MyProjectName (name@studenti.univr.it)',\n",
        "                                   'en',\n",
        "                                   extract_format=wikipediaapi.ExtractFormat.WIKI)"
      ],
      "metadata": {
        "id": "f2ymnwhM7PGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "page_py = wapi_text.page('New York City')\n",
        "print(\"Page - Exists: {}\".format( page_py.exists()))\n",
        "print(len(page_py.summary))\n",
        "print(len(page_py.text))\n",
        "print(len(page_py.langlinks))\n",
        "print(len(page_py.links))"
      ],
      "metadata": {
        "id": "9peoLRdX5yfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(page_py.summary[:140])\n",
        "print(\"   ---   \")\n",
        "print(page_py.text[-140:])\n",
        "print(\"   ---   \")\n",
        "print(sorted(page_py.langlinks.keys()))\n",
        "print(\"   ---   \")\n",
        "page_py_it = page_py.langlinks['it']\n",
        "print(page_py_it.summary[:140])"
      ],
      "metadata": {
        "id": "pK-HhvuAOBXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "links = page_py.links\n",
        "for title in sorted(links.keys()):\n",
        "    if len(title) > 4 : # filter on title length to reduce output\n",
        "      continue\n",
        "    print(\"{}\".format(title))"
      ],
      "metadata": {
        "id": "DmrRNRqTOcRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pages = ['Addis Ababa',  'Tom Sawyer', 'Johannes Gutenberg']"
      ],
      "metadata": {
        "id": "dBmBbb925bLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.parse import quote\n",
        "\n",
        "page_queue = [ wapi_text.page(tp) for  tp in test_pages ]\n",
        "page_stored = {}\n",
        "page_visited = set()\n",
        "max_iterations = 50\n",
        "\n",
        "while len(page_queue) > 0 and max_iterations > 0:\n",
        "  _page = page_queue.pop()\n",
        "\n",
        "  page_stored[_page.fullurl] = _page.summary\n",
        "\n",
        "  page_visited.add(_page.fullurl)\n",
        "\n",
        "  print(max_iterations, _page.title, _page.fullurl)\n",
        "  max_iterations = max_iterations - 1\n",
        "\n",
        "  for next_page in _page.links.values():\n",
        "    try:\n",
        "      if len(next_page.title) < 6 and len(next_page.title) > 13:\n",
        "        continue # skip this page\n",
        "\n",
        "      if ':' in next_page.title :\n",
        "        continue\n",
        "\n",
        "      if next_page.fullurl in page_visited:\n",
        "        continue # skip this page\n",
        "\n",
        "      # otherwise\n",
        "      page_queue.append(next_page)\n",
        "    except:\n",
        "      print(\"Error retrieving\", next_page.title)\n",
        "\n",
        "\n",
        "print(len(page_stored))\n",
        "print(page_stored.keys())"
      ],
      "metadata": {
        "id": "fQSrh1c2Vp-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "page_stored['https://en.wikipedia.org/wiki/Victoria_Falls_Airport']"
      ],
      "metadata": {
        "id": "WiWiNnsliV0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######\n",
        "# TODO: Create the bag of words for all page summaries, remember to transform the text in lowercase and remove punctuation\n",
        "######"
      ],
      "metadata": {
        "id": "pa8-zAiMk2sV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The following declaration extract unparsed HTML instead of already parsed text"
      ],
      "metadata": {
        "id": "DLpeEL5_VyYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wapi_html = wikipediaapi.Wikipedia('MyProjectName (name@studenti.univr.it)',\n",
        "                              'en',\n",
        "                              extract_format=wikipediaapi.ExtractFormat.HTML)\n",
        "page_py = wapi_text.page('New York City')\n",
        "print(\"Page - Exists: {}\".format( page_py.exists()))\n",
        "print(len(page_py.summary))\n"
      ],
      "metadata": {
        "id": "OW8WNKmAUOKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stemming nad lemmatization"
      ],
      "metadata": {
        "id": "CRPkFNA_la_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import PorterStemmer, SnowballStemmer, WordNetLemmatizer\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"omw-1.4\")"
      ],
      "metadata": {
        "id": "a-XhpJaflOAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Python porter stemmer\n",
        "ps = PorterStemmer()\n",
        "sn = SnowballStemmer(\"english\")\n",
        "\n",
        "example_sentence = \"Programming is an art and a job. Python programmers often tend to like programming in python because it's like english. This is a better language than many ohters an incredibly useful property that makes things easier. We call people who program in python pythonistas.\"\n",
        "\n",
        "# Remove punctuation\n",
        "example_sentence_no_punct = example_sentence.lower().translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "\n",
        "# Create tokens\n",
        "word_tokens = word_tokenize(example_sentence_no_punct)\n",
        "\n",
        "# Perform stemming\n",
        "print(\"{0:20}{1:20}\".format(\"--Word--\",\"--Stem--\"))\n",
        "for word in word_tokens:\n",
        "    print (\"{0:20}{1:20}{2:20}\".format(word, ps.stem(word), sn.stem(word)))\n"
      ],
      "metadata": {
        "id": "GsJe2dKErAWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize wordnet lemmatizer\n",
        "wnl = WordNetLemmatizer()\n",
        "\n",
        "# wn.VERB\n",
        "# wn.ADV\n",
        "# wn.NOUN\n",
        "\n",
        "# Perform lemmatization\n",
        "print(\"{0:20}{1:20}\".format(\"--Word--\",\"--Lemma--\"))\n",
        "for word in word_tokens:\n",
        "   print (\"{0:20}{1:20}\".format(word, wnl.lemmatize(word, pos=wordnet.ADJ))) # <- lemmatize as if they are all adjectives\n",
        ""
      ],
      "metadata": {
        "id": "u_naQ1fJn91E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######\n",
        "# TODO: Text stemming and lemmatization with a wikipedia page summary\n",
        "######\n",
        "\n"
      ],
      "metadata": {
        "id": "Y5H2bN1dV2nq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}